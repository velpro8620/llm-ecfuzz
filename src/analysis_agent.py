import json
from typing import List, Dict, Any
from langchain.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

# å°è¯•å¯¼å…¥ RAG æ¨¡å—
try:
    from fuzzer.RAG import get_vectorstore
except ImportError:
    try:
        from RAG import get_vectorstore
    except ImportError:
        import sys, os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from fuzzer.RAG import get_vectorstore

# å°è¯•å¯¼å…¥ json_repair
try:
    import json_repair
    HAS_JSON_REPAIR = True
except ImportError:
    HAS_JSON_REPAIR = False

def clean_json_text(text: str) -> str:
    text = text.strip()
    if text.startswith("```"):
        lines = text.splitlines()
        if lines and lines[0].strip().startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        text = "\n".join(lines).strip()
    
    start = text.find("{")
    end = text.rfind("}")
    if start != -1 and end != -1 and end >= start:
        text = text[start : end + 1]
    return text

class AnalysisAgent:
    """
    é…ç½®ä¾èµ–åˆ†æ Agent (æ”¯æŒæ™ºèƒ½è·¯ç”±æ£€ç´¢)
    """

    # é¢„å®šä¹‰å‘é‡åº“ä¸­å·²æœ‰çš„â€œæ ‡å‡†å‚è€ƒä¹¦ç›®â€
    # ä½ å¯ä»¥æ ¹æ®å®é™… default_conf_file é‡Œçš„å†…å®¹ä¿®æ”¹è¿™ä¸ªåˆ—è¡¨
    KNOWN_FILES = [
        "core-default.xml",
        "hdfs-default.xml",
        "hbase-default.xml", 
        "zoo.cfg",
        "alluxio-site.properties"
    ]

    def __init__(
        self,
        api_key: str,
        base_url: str,
        model_name: str,
        temperature: float = 0.1,
        max_tokens: int = 32768,
        request_timeout: int = 120,
        use_rag: bool = True
    ):
        self.llm = ChatOpenAI(
            model_name=model_name,
            api_key=api_key,
            base_url=base_url,
            temperature=temperature,
            max_tokens=max_tokens,
            request_timeout=request_timeout,
        )
        
        self.use_rag = use_rag
        self.vectorstore = None
        
        if self.use_rag:
            try:
                self.vectorstore = get_vectorstore()
                if self.vectorstore:
                    print("[AnalysisAgent] âœ… RAG å‘é‡åº“è¿æ¥æˆåŠŸ")
                else:
                    self.use_rag = False
            except Exception as e:
                print(f"[AnalysisAgent] âš ï¸ RAG åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_rag = False

    def _determine_scope(self, content_snippet: str) -> List[str]:
        """
        [æ™ºèƒ½è·¯ç”±]ï¼šæ ¹æ®è¾“å…¥æ–‡ä»¶ç‰‡æ®µï¼Œåˆ¤æ–­éœ€è¦æ£€ç´¢å“ªäº›ç›¸å…³æ–‡ä»¶ã€‚
        """
        system_msg = SystemMessage(content=(
            "ä½ æ˜¯ä¸€ä¸ªå¤§æ•°æ®ç»„ä»¶ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„é…ç½®æ–‡ä»¶ç‰‡æ®µï¼Œåˆ¤æ–­è¯¥æ–‡ä»¶å±äºå“ªä¸ªç»„ä»¶ï¼ˆå¦‚ HDFS, HBase, ZooKeeper ç­‰ï¼‰ï¼Œ"
            "å¹¶æ¨æ–­åˆ†æè¯¥é…ç½®å¯èƒ½éœ€è¦å‚è€ƒå“ªäº›ä¸Šæ¸¸ä¾èµ–æ–‡ä»¶ã€‚\n"
            f"å¯é€‰çš„æ–‡ä»¶åˆ—è¡¨ä¸ºï¼š{json.dumps(self.KNOWN_FILES)}\n"
            "è¯·è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼ä¸ºï¼š{\"relevant_files\": [\"file1\", \"file2\"]}\n"
            "æ³¨æ„ï¼šå¿…é¡»åŒ…å«æ–‡ä»¶è‡ªèº«ï¼ˆå¦‚æœå®ƒåœ¨åˆ—è¡¨é‡Œï¼‰ï¼Œä»¥åŠå®ƒç›´æ¥ä¾èµ–çš„ç»„ä»¶ï¼ˆä¾‹å¦‚ HBase ä¾èµ– HDFS å’Œ ZooKeeperï¼‰ã€‚"
        ))
        
        human_msg = HumanMessage(content=f"é…ç½®æ–‡ä»¶ç‰‡æ®µï¼š\n{content_snippet}")
        
        try:
            # ä½¿ç”¨ LLM å¿«é€Ÿåˆ¤æ–­
            response = self.llm.invoke([system_msg, human_msg])
            result = json.loads(clean_json_text(response.content))
            files = result.get("relevant_files", [])
            # è¿‡æ»¤æ‰ä¸åœ¨æˆ‘ä»¬åˆ—è¡¨é‡Œçš„å¹»è§‰æ–‡ä»¶
            valid_files = [f for f in files if f in self.KNOWN_FILES]
            return valid_files
        except Exception as e:
            print(f"[AnalysisAgent] âš ï¸ è·¯ç”±åˆ†æå¤±è´¥: {e}ï¼Œå°†å›é€€åˆ°å…¨åº“æ£€ç´¢")
            return [] # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºä¸è¿›è¡Œè¿‡æ»¤ï¼ˆå…¨åº“æ£€ç´¢ï¼‰

    def _retrieve_context(self, content_input: str) -> str:
        if not self.use_rag or not self.vectorstore:
            return ""
        
        # 1. æˆªå–å‰ 1000 å­—ç¬¦ç”¨äºè·¯ç”±åˆ¤æ–­ï¼ˆè¶³å¤Ÿè¯†åˆ«æ˜¯å“ªä¸ªç»„ä»¶äº†ï¼‰
        snippet = content_input[:1000]
        
        # 2. [æ–°å¢] æ™ºèƒ½è·¯ç”±ï¼šå†³å®šè¦æŸ¥å“ªäº›æ–‡ä»¶
        print("[AnalysisAgent] ğŸ¤– æ­£åœ¨åˆ†ææ–‡ä»¶ç±»å‹åŠä¾èµ–èŒƒå›´...")
        target_files = self._determine_scope(snippet)
        
        search_kwargs = {"k": 5}
        
        # 3. [æ–°å¢] æ„é€ è¿‡æ»¤å™¨
        if target_files:
            print(f"[AnalysisAgent] ğŸ¯ é”å®šæ£€ç´¢èŒƒå›´: {target_files}")
            # ChromaDB çš„ $in è¯­æ³•ï¼š {"filename": {"$in": [...]}}
            search_kwargs["filter"] = {"filename": {"$in": target_files}}
        else:
            print("[AnalysisAgent] ğŸŒ æœªè¯†åˆ«ç‰¹å®šèŒƒå›´ï¼Œæ‰§è¡Œå…¨åº“æ£€ç´¢")

        # 4. æ‰§è¡Œæ£€ç´¢
        query = content_input[:300].replace("\n", " ") # ç”¨å‰300å­—åšè¯­ä¹‰æŸ¥è¯¢
        try:
            results = self.vectorstore.similarity_search(query, **search_kwargs)
            
            if not results:
                print("[AnalysisAgent] âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹")
                return ""

            context = "\n".join([f"---å‚è€ƒé…ç½® ({doc.metadata.get('filename')})---\n{doc.page_content}" for doc in results])
            return context
        except Exception as e:
            print(f"[AnalysisAgent] æ£€ç´¢æ‰§è¡Œå‡ºé”™: {e}")
            return ""

    @staticmethod
    def _build_messages(config_content: str, rag_context: str = "") -> List:
        system_msg = SystemMessage(
            content=(
                "ä½ æ˜¯ä¸€ä¸ªé…ç½®å‚æ•°åˆ†æä¸“å®¶ã€‚è¯·åˆ†æé…ç½®å‚æ•°ä¹‹é—´çš„ä»¥ä¸‹ä¾èµ–å…³ç³»ç±»å‹ï¼š\n"
                "1. æ§åˆ¶ä¾èµ– (Control Dependency)\n"
                "2. å€¼å…³ç³»ä¾èµ– (Value Dependency)\n"
                "3. é»˜è®¤å€¼ä¾èµ– (Default Value Dependency)\n"
                "4. è¡Œä¸ºä¾èµ– (Behavioral Dependency)\n"
                "è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–æ–‡æœ¬ã€‚"
            )
        )

        context_prompt = ""
        if rag_context:
            context_prompt = (
                f"\n\nã€å‚è€ƒçŸ¥è¯†åº“ (å·²è¿‡æ»¤ç›¸å…³ç»„ä»¶)ã€‘\n"
                f"{rag_context}\n"
                f"--------------------------------\n"
                f"è¯·ç»“åˆä¸Šè¿°å‚è€ƒèµ„æ–™ï¼ˆç‰¹åˆ«æ˜¯è·¨ç»„ä»¶çš„å‚æ•°å¼•ç”¨ï¼‰è¿›è¡Œåˆ†æã€‚\n"
            )

        # æˆªæ–­ä¿æŠ¤
        if len(config_content) > 100000:
            print(f"[AnalysisAgent] âš ï¸ é…ç½®å†…å®¹è¿‡é•¿ ({len(config_content)} chars)ï¼Œå·²æˆªå–å‰ 100000 å­—ç¬¦...")
            config_content = config_content[:100000] + "\n... (truncated)"

        human_msg = HumanMessage(
            content=(
                f"{context_prompt}"
                "è¯·åˆ†æä»¥ä¸‹é…ç½®å†…å®¹çš„å‚æ•°ä¾èµ–å…³ç³»ï¼š\n"
                "```xml\n"
                f"{config_content}\n"
                "```\n"
                "è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š\n"
                "{\n"
                '  "dependencies": [\n'
                "    {\n"
                '      "source": "æºå‚æ•°", "target": "ç›®æ ‡å‚æ•°", "type": "ä¾èµ–ç±»å‹", "relationship": "æè¿°"\n'
                "    }\n"
                "  ]\n"
                "}\n"
            )
        )
        return [system_msg, human_msg]

    def analyze_config_dependencies(self, config_content: str) -> dict:
        # 1. è·¯ç”± + æ£€ç´¢
        rag_context = self._retrieve_context(config_content)
        
        # 2. æ„é€ åˆ†æ Prompt
        messages = self._build_messages(config_content, rag_context)
        
        print("[AnalysisAgent] ğŸ§  æ­£åœ¨è¿›è¡Œæ·±åº¦ä¾èµ–åˆ†æ...")
        response = self.llm.invoke(messages)
        
        cleaned_text = clean_json_text(response.content)
        
        try:
            return json.loads(cleaned_text)
        except json.JSONDecodeError as e:
            print(f"\n[AnalysisAgent] âŒ JSON è§£æå¤±è´¥: {e}")
            if HAS_JSON_REPAIR:
                print("[AnalysisAgent] ğŸ”„ å°è¯•è‡ªåŠ¨ä¿®å¤ JSON...")
                try:
                    return json_repair.loads(cleaned_text)
                except Exception:
                    return {"dependencies": []}
            else:
                return {"dependencies": []}
